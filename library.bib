Automatically generated by Mendeley Desktop 1.17.11
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Badrinarayanan2015,
abstract = {We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation termed SegNet. This core trainable segmentation engine consists of an encoder network, a corresponding decoder network followed by a pixel-wise classification layer. The architecture of the encoder network is topologically identical to the 13 convolutional layers in the VGG16 network. The role of the decoder network is to map the low resolution encoder feature maps to full input resolution feature maps for pixel-wise classification. The novelty of SegNet lies is in the manner in which the decoder upsamples its lower resolution input feature map(s). Specifically, the decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. This eliminates the need for learning to upsample. The upsampled maps are sparse and are then convolved with trainable filters to produce dense feature maps. We compare our proposed architecture with the widely adopted FCN and also with the well known DeepLab-LargeFOV, DeconvNet architectures. This comparison reveals the memory versus accuracy trade-off involved in achieving good segmentation performance. SegNet was primarily motivated by scene understanding applications. Hence, it is designed to be efficient both in terms of memory and computational time during inference. It is also significantly smaller in the number of trainable parameters than other competing architectures. We also performed a controlled benchmark of SegNet and other architectures on both road scenes and SUN RGB-D indoor scene segmentation tasks. We show that SegNet provides good performance with competitive inference time and more efficient inference memory-wise as compared to other architectures. We also provide a Caffe implementation of SegNet and a web demo at http://mi.eng.cam.ac.uk/projects/segnet/.},
archivePrefix = {arXiv},
arxivId = {1511.00561},
author = {Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
doi = {10.1109/TPAMI.2016.2644615},
eprint = {1511.00561},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/1511.00561.pdf:pdf},
isbn = {9783319464879},
issn = {0162-8828},
pages = {1--14},
pmid = {28060704},
title = {{SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation}},
url = {http://arxiv.org/abs/1511.00561},
year = {2015}
}
@misc{powertrace2016,
author = {PowerTRACE},
title = {{Taking Corel PowerTRACE for a Test Drive – Knowledge Base}},
url = {https://support.corel.com/hc/en-us/articles/215943948-Taking-Corel-PowerTRACE-for-a-Test-Drive},
urldate = {2017-10-24},
year = {2016}
}
@misc{scan2cad2009,
author = {Scan2cad},
title = {{Scan2CAD in Landscape Architecture}},
url = {https://www.scan2cad.com/user-testimony/scan2cad-in-landscape-architecture/},
urldate = {2017-10-24},
year = {2009}
}
@article{Schalkoff1989,
author = {Schalkoff, R J},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/Schalkoff - 1989 - Feature Extraction And Shape Classification Of 2-D Polygons Using A Neural Network.pdf:pdf},
pages = {953--958},
title = {{Feature Extraction And Shape Classification Of 2-D Polygons Using A Neural Network}},
year = {1989}
}
@article{Karabork2008,
abstract = {In the last twenty-five years a great number of vectorization methods were developed. In this paper we first give an overview about the most known methods, and then propose a vectorization algorithm based on Artificial Neural Network method. This algorithm is implemented by using C{\#} programming language. Because distortions in size and location after vectorization are important for mapping applications, we tested our algorithm and software on a cadastral map. We also compared the results of our algorithm with the results of Sparse Pixel Vectorization (SPV) algorithm. Although SPV algorithm delivers better results, our algorithm also givesacceptable results, which are suitable for mapping purposes.},
author = {Karabork, H and Kocer, B. and Bildirici, I O and Yildiz, F. and Aktas, E.},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/Karabork et al. - 2008 - A neural network algorithm for vectorization of 2D maps.pdf:pdf},
journal = {[APRS'08] International Archives of Photogrammetry and Remote Sensing},
keywords = {accuracy,analysis,artificial{\_}intelligence,cad,image,information,spatial information sciences,tracking},
number = {B2},
pages = {473--480},
title = {{A neural network algorithm for vectorization of 2D maps}},
volume = {XXXVII},
year = {2008}
}
@article{Chiang2013,
abstract = {Raster maps are easily accessible and contain rich road information; however, converting the road information to vector format is challenging because of varying image quality, overlapping features, and typical lack of metadata (e.g., map geocoordinates). Previous road vectorization approaches for raster maps typically handle a specific map series and require significant user effort. In this paper, we present a general road vectorization approach that exploits common geometric properties of roads in maps for processing heterogeneous raster maps while requiring minimal user intervention. In our experiments, we compared our approach to a widely used commercial product using 40 raster maps from 11 sources. We showed that overall our approach generated high-quality results with low redundancy with considerably less user input compared with competing approaches.},
author = {Chiang, Yao Yi and Knoblock, Craig A.},
doi = {10.1007/s10032-011-0177-1},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/Chiang, Knoblock - 2013 - A general approach for extracting road vector data from raster maps.pdf:pdf},
isbn = {9783642330230},
issn = {14332833},
journal = {International Journal on Document Analysis and Recognition},
keywords = {GIS,Map processing,Raster maps,Road vectorization},
number = {1},
pages = {55--81},
title = {{A general approach for extracting road vector data from raster maps}},
volume = {16},
year = {2013}
}
@article{Pearson2006,
annote = {Kilde p{\aa} hvorfor digitalisering av gamle kart kan v{\ae}re verdifult},
author = {Pearson, Alastair W},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/Pearson.pdf:pdf},
keywords = {agricultural history,georeferencing,gis,multilevel modelling,tithe maps},
number = {3},
pages = {178--193},
title = {{Digitizing and analyzing historical maps to provide new perspectives on the development of the agricultural landscape of England and Wales}},
volume = {1},
year = {2006}
}
@article{Daniil2003,
abstract = {The introduction of modern digital imaging techniques to historical cartography, especially in documenting old map collections, meets the need for extending and applying image processing and relevant photogrammetric tools to the analysis of antique maps in a context in which digital photogrammetry intersects modern theories of digital treatment of old maps. The authors discuss some aspects of controlling the geometric features of the scanned images of antique maps in terms, e.g., of linear, angular, and areal deformation. Collateral effects influencing the scanned map image are also described--namely, the statistics and the image quality of the output map images with respect to the original map and/or the "reference" digital best-scanned image.},
author = {Daniil, M and Tsioukas, V and Papadopoulos, K and Livieratos, E},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/Scanning{\_}options{\_}and{\_}choices{\_}in{\_}digitizing{\_}histori.pdf:pdf},
isbn = {975-561-245-9},
journal = {Proceedings of the XIXth International Symposium, CIPA 2003: new perspectives to save cultural heritage: Antalya (Turkey), 30 September-04 October, 2003},
keywords = {cartography,data processing,digital imaging,maps,photogrammetry},
number = {January},
pages = {99--102},
title = {{Scanning options and choices in digitizing historic maps}},
year = {2003}
}
@article{Iosifescu2016,
abstract = {Historical maps from different periods of time are very important for many types of research. They can show the development of a place through the time and their use can be profitable in different studies concerning the geographic analysis of terrain, en- vironmental changes and the development of landscape and settlements in a specific area. These spatial changes are many times preserved only through maps that are often available only in analogue form or, in the best case, as scanned raster images. Since the scanning of these maps is not always sufficient for their further analysis, it is useful and practical to have historical maps in vector form and the most important, to have a method to automati- cally convert the raster historical maps to vector data. The extracted vector data gives re- searchers and historians the opportunity to detect and determine more easily spatial chang- es in an area over time and also makes easier the combination and the analysis of historical and modern data in order to highlight in a faster manner the differences between maps dated on various time periods.},
author = {Iosifescu, Ionut and Tsorlini, Angeliki and Hurni, Lorenz},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/Iosifescu, Tsorlini, Hurni - 2016 - Towards a comprehensive methodology for automatic vectorization of raster historical maps.pdf:pdf},
journal = {e-Perimetron},
keywords = {automatic vectorization,historical maps,raster to vector,shape recognition,vectorization algorithms},
number = {2},
pages = {57--76},
title = {{Towards a comprehensive methodology for automatic vectorization of raster historical maps}},
volume = {11},
year = {2016}
}
@article{Armstrong2006,
author = {Armstrong, Curtis A},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/Armstrong - 2006 - Vectorization of Raster Images Using B-Spline Surfaces.pdf:pdf},
keywords = {vector video research preparation,矢量视频调研},
number = {July},
pages = {166},
title = {{Vectorization of Raster Images Using B-Spline Surfaces}},
year = {2006}
}
@article{Chiang2013,
abstract = {Raster maps are easily accessible and contain rich road information; however, converting the road information to vector format is challenging because of varying image quality, overlapping features, and typical lack of metadata (e.g., map geocoordinates). Previous road vectorization approaches for raster maps typically handle a specific map series and require significant user effort. In this paper, we present a general road vectorization approach that exploits common geometric properties of roads in maps for processing heterogeneous raster maps while requiring minimal user intervention. In our experiments, we compared our approach to a widely used commercial product using 40 raster maps from 11 sources. We showed that overall our approach generated high-quality results with low redundancy with considerably less user input compared with competing approaches.},
annote = {Hough Transform for {\aa} f{\aa} frem ganske gode resultater.},
author = {Chiang, Yao Yi and Knoblock, Craig A.},
doi = {10.1007/s10032-011-0177-1},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/Chiang, Knoblock - 2013 - A general approach for extracting road vector data from raster maps.pdf:pdf},
isbn = {9783642330230},
issn = {14332833},
journal = {International Journal on Document Analysis and Recognition},
keywords = {GIS,Map processing,Raster maps,Road vectorization},
number = {1},
pages = {55--81},
title = {{A general approach for extracting road vector data from raster maps}},
volume = {16},
year = {2013}
}
@article{Krizhevsky2012,
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSRVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5{\%} and 17.0{\%} which is considerably better than the previous state of the art. The neural network, which has 60 million paramters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolutional operation. To reduce overfitting in the fully-connected layers, we employed a recently-developed method called 'dropout' that proved to be effective. We also entered a variant of the model in the ILSVRC-2012 competition and achievd a top-5 test error rate of 15.3{\%}, compared to 26.2{\%} achieved by the second-best entry.},
archivePrefix = {arXiv},
arxivId = {1102.0183},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
doi = {http://dx.doi.org/10.1016/j.protcy.2014.09.007},
eprint = {1102.0183},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf:pdf},
isbn = {9781627480031},
issn = {10495258},
journal = {Advances In Neural Information Processing Systems},
pages = {1--9},
pmid = {7491034},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
year = {2012}
}
@misc{powertrace2016,
author = {PowerTRACE},
title = {{Taking Corel PowerTRACE for a Test Drive – Knowledge Base}},
url = {https://support.corel.com/hc/en-us/articles/215943948-Taking-Corel-PowerTRACE-for-a-Test-Drive},
urldate = {2017-10-24},
year = {2016}
}
@article{Karabork2008,
abstract = {In the last twenty-five years a great number of vectorization methods were developed. In this paper we first give an overview about the most known methods, and then propose a vectorization algorithm based on Artificial Neural Network method. This algorithm is implemented by using C{\#} programming language. Because distortions in size and location after vectorization are important for mapping applications, we tested our algorithm and software on a cadastral map. We also compared the results of our algorithm with the results of Sparse Pixel Vectorization (SPV) algorithm. Although SPV algorithm delivers better results, our algorithm also givesacceptable results, which are suitable for mapping purposes.},
author = {Karabork, H and Kocer, B. and Bildirici, I O and Yildiz, F. and Aktas, E.},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/Karabork et al. - 2008 - A neural network algorithm for vectorization of 2D maps.pdf:pdf},
journal = {[APRS'08] International Archives of Photogrammetry and Remote Sensing},
keywords = {accuracy,analysis,artificial{\_}intelligence,cad,image,information,spatial information sciences,tracking},
number = {B2},
pages = {473--480},
title = {{A neural network algorithm for vectorization of 2D maps}},
volume = {XXXVII},
year = {2008}
}
@article{He2015,
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57{\%} error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28{\%} relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC {\&} COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
archivePrefix = {arXiv},
arxivId = {1512.03385},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
doi = {10.1007/s11042-017-4440-4},
eprint = {1512.03385},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/1512.03385.pdf:pdf},
isbn = {978-1-4673-6964-0},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {Convolutional neural networks,Image steganalysis,Residual learning},
pages = {1--17},
pmid = {23554596},
title = {{Deep Residual Learning for Image Recognition}},
year = {2015}
}
@article{Schalkoff1989,
author = {Schalkoff, R J},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/Schalkoff - 1989 - Feature Extraction And Shape Classification Of 2-D Polygons Using A Neural Network.pdf:pdf},
pages = {953--958},
title = {{Feature Extraction And Shape Classification Of 2-D Polygons Using A Neural Network}},
year = {1989}
}
@article{Sabour2017,
abstract = {A capsule is a group of neurons whose activity vector represents the instantiation parameters of a specific type of entity such as an object or object part. We use the length of the activity vector to represent the probability that the entity exists and its orientation to represent the instantiation paramters. Active capsules at one level make predictions, via transformation matrices, for the instantiation parameters of higher-level capsules. When multiple predictions agree, a higher level capsule becomes active. We show that a discrimininatively trained, multi-layer capsule system achieves state-of-the-art performance on MNIST and is considerably better than a convolutional net at recognizing highly overlapping digits. To achieve these results we use an iterative routing-by-agreement mechanism: A lower-level capsule prefers to send its output to higher level capsules whose activity vectors have a big scalar product with the prediction coming from the lower-level capsule. The final version of the paper is under revision to encorporate reviewers comments.},
archivePrefix = {arXiv},
arxivId = {1710.09829},
author = {Sabour, Sara and Frosst, Nicholas and Hinton, Geoffrey},
eprint = {1710.09829},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/1710.09829.pdf:pdf},
journal = {Nips},
number = {Nips},
title = {{Dynamic Routing between Capsules}},
url = {https://research.google.com/pubs/pub46351.html},
year = {2017}
}
@article{Lee2000,
abstract = {Developing an automated vectorizing system as an input method for a geographic information system (GIS) is of extreme importance due to the fact that an input process takes a lot of time and cost in constructing a GIS. Most vectorizing systems require users to set the parameters as appropriately as possible for a particular map image, but it is quite difficult for a novice to adjust the parameters appropriately. This paper proposes a knowledge-based system for automated vectorization, allowing an appropriate choice of the parameters. Since thinning of the input image to produce a skeleton of unit width is a prerequisite for the automated vectorization among several steps, the performance of representative thinning algorithms is systematically evaluated in various map images, and appropriate rules for the maps are devised. Each rule in the knowledge base is characterized by the type of map, and by the resolution, line width, slope and protrusions. Experimental results with various map images show that the proposed system is superior in terms of performance and convenience of use.},
annote = {Kilde p{\aa} hvorfor digitalisering av gamle kart kan v{\ae}re verdifult},
author = {Lee, Kyong Ho and Cho, Sung Bae and Choy, Yoon Chul},
doi = {10.1016/S0952-1976(99)00049-4},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/1-s2.0-S0952197699000494-main.pdf:pdf},
isbn = {8223612712},
issn = {09521976},
journal = {Engineering Applications of Artificial Intelligence},
keywords = {automated vectorization,cartographic maps,geographic information systems,knowledge bases,thinning},
number = {2},
pages = {165--178},
title = {{Automated vectorization of cartographic maps by a knowledge-based system}},
volume = {13},
year = {2000}
}
@article{Simonyan2014a,
abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
archivePrefix = {arXiv},
arxivId = {1409.1556},
author = {Simonyan, Karen and Zisserman, Andrew},
doi = {10.1016/j.infsof.2008.09.005},
eprint = {1409.1556},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/1409.1556.pdf:pdf},
isbn = {0950-5849},
issn = {09505849},
pages = {1--14},
pmid = {16873662},
title = {{Very Deep Convolutional Networks for Large-Scale Image Recognition}},
url = {http://arxiv.org/abs/1409.1556},
year = {2014}
}
@article{Russakovsky2015,
abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the five years of the challenge, and propose future directions and improvements.},
archivePrefix = {arXiv},
arxivId = {1409.0575},
author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
doi = {10.1007/s11263-015-0816-y},
eprint = {1409.0575},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/1409.0575.pdf:pdf},
isbn = {0920-5691},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Benchmark,Dataset,Large-scale,Object detection,Object recognition},
number = {3},
pages = {211--252},
pmid = {16190471},
title = {{ImageNet Large Scale Visual Recognition Challenge}},
volume = {115},
year = {2015}
}
@article{Song2000,
author = {Song, Jiqiang and Su, Feng and Chen, Jibing and Cai, Shijie},
doi = {10.1007/s100440070019},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/10.1007{\%}2Fs100440070019.pdf:pdf},
issn = {1433-7541},
journal = {Pattern Analysis {\&} Applications},
keywords = {global vectorisation,knowledge,line network,seed segment,tracking,vectorisation},
number = {2},
pages = {142--152},
title = {{A Knowledge-Aided Line Network Oriented Vectorisation Method for Engineering Drawings}},
volume = {3},
year = {2000}
}
@article{Leyk2010,
abstract = {A novel approach to color image segmentation (CIS) in scanned archival topographic maps of the 19th century is presented. Archival maps provide unique information for GIS-based change detection and are the only spatially contiguous data sources prior to the establishment of remote sensing. Processing such documents is challenging due to their very low graphical quality caused by ageing, manual production and scanning. Typical artifacts are high degrees of mixed and false coloring, as well as blurring in the images. Existing approaches for segmentation in cartographic documents are normally presented using well-conditioned maps. The CIS approach presented here uses information from the local image plane, the frequency domain and color space. As a first step, iterative clustering is based on local homogeneity, frequency of homogeneity-tested pixels and similarity. By defining a peak-finding rule, "hidden" color layer prototypes can be identified without prior knowledge. Based on these prototypes a constrained seeded region growing (SRG) process is carried out to find connected regions of color layers using color similarity and spatial connectivity. The method was tested on map pages with different graphical properties with robust results as derived from an accuracy assessment.},
author = {Leyk, Stefan and Boesch, Ruedi},
doi = {10.1007/s10707-008-0074-z},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/10.1007{\%}2Fs10707-008-0074-z.pdf:pdf},
isbn = {1070700800},
issn = {13846175},
journal = {GeoInformatica},
keywords = {Clustering,Color image segmentation,Constrained seeded region growing,GIS,Local homogeneity,Peak-finding,Topographic maps},
number = {1},
pages = {1--21},
title = {{Colors of the past: Color image segmentation in historical topographic maps based on homogeneity}},
volume = {14},
year = {2010}
}
@misc{Kommunaltplanregister2009,
author = {Kommunalt planregister},
title = {{{\S} 2-2. Kommunalt planregister}},
url = {https://www.regjeringen.no/no/dokument/dep/kmd/veiledninger{\_}brosjyrer/2009/lovkommentar-til-plandelen-i-/kapittel-2-krav-om-kartgrunnlag-stedfest/-2-2-kommunalt-planregister/id556741/},
year = {2009}
}
@article{Chen2017,
abstract = {In histopathological image analysis, the morphology of histological structures, such as glands and nuclei, has been routinely adopted by pathologists to assess the malignancy degree of adenocarcinomas. Accurate detection and segmentation of these objects of interest from histology images is an essential prerequisite to obtain reliable morphological statistics for quantitative diagnosis. While manual annotation is error-prone, time-consuming and operator-dependant, automated detection and segmentation of objects of interest from histology images can be very challenging due to the large appearance variation, existence of strong mimics, and serious degeneration of histological structures. In order to meet these challenges, we propose a novel deep contour-aware network (DCAN) under a unified multi-task learning framework for more accurate detection and segmentation. In the proposed network, multi-level contextual features are explored based on an end-to-end fully convolutional network (FCN) to deal with the large appearance variation. We further propose to employ an auxiliary supervision mechanism to overcome the problem of vanishing gradients when training such a deep network. More importantly, our network can not only output accurate probability maps of histological objects, but also depict clear contours simultaneously for separating clustered object instances, which further boosts the segmentation performance. Our method ranked the first in two histological object segmentation challenges, including 2015 MICCAI Gland Segmentation Challenge and 2015 MICCAI Nuclei Segmentation Challenge. Extensive experiments on these two challenging datasets demonstrate the superior performance of our method, surpassing all the other methods by a significant margin.},
archivePrefix = {arXiv},
arxivId = {1604.02677},
author = {Chen, Hao and Qi, Xiaojuan and Yu, Lequan and Dou, Qi and Qin, Jing and Heng, Pheng Ann},
doi = {10.1016/j.media.2016.11.004},
eprint = {1604.02677},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/histology-instace-segmentation.pdf:pdf},
isbn = {9781467388511},
issn = {13618423},
journal = {Medical Image Analysis},
keywords = {Deep contour-aware network,Deep learning,Histopathological image analysis,Instance segmentation,Object detection,Transfer learning},
pages = {135--146},
pmid = {27898306},
publisher = {Elsevier B.V.},
title = {{DCAN: Deep contour-aware networks for object instance segmentation from histology images}},
url = {http://dx.doi.org/10.1016/j.media.2016.11.004},
volume = {36},
year = {2017}
}
@misc{scan2cad2009,
author = {Scan2cad},
title = {{Scan2CAD in Landscape Architecture}},
url = {https://www.scan2cad.com/user-testimony/scan2cad-in-landscape-architecture/},
urldate = {2017-10-24},
year = {2009}
}
@article{Iosifescu2016,
abstract = {Historical maps from different periods of time are very important for many types of research. They can show the development of a place through the time and their use can be profitable in different studies concerning the geographic analysis of terrain, en- vironmental changes and the development of landscape and settlements in a specific area. These spatial changes are many times preserved only through maps that are often available only in analogue form or, in the best case, as scanned raster images. Since the scanning of these maps is not always sufficient for their further analysis, it is useful and practical to have historical maps in vector form and the most important, to have a method to automati- cally convert the raster historical maps to vector data. The extracted vector data gives re- searchers and historians the opportunity to detect and determine more easily spatial chang- es in an area over time and also makes easier the combination and the analysis of historical and modern data in order to highlight in a faster manner the differences between maps dated on various time periods.},
author = {Iosifescu, Ionut and Tsorlini, Angeliki and Hurni, Lorenz},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/Iosifescu, Tsorlini, Hurni - 2016 - Towards a comprehensive methodology for automatic vectorization of raster historical maps.pdf:pdf},
journal = {e-Perimetron},
keywords = {automatic vectorization,historical maps,raster to vector,shape recognition,vectorization algorithms},
number = {2},
pages = {57--76},
title = {{Towards a comprehensive methodology for automatic vectorization of raster historical maps}},
volume = {11},
year = {2016}
}
@article{Garcia-Garcia2017,
abstract = {Image semantic segmentation is more and more being of interest for computer vision and machine learning researchers. Many applications on the rise need accurate and efficient segmentation mechanisms: autonomous driving, indoor navigation, and even virtual or augmented reality systems to name a few. This demand coincides with the rise of deep learning approaches in almost every field or application target related to computer vision, including semantic segmentation or scene understanding. This paper provides a review on deep learning methods for semantic segmentation applied to various application areas. Firstly, we describe the terminology of this field as well as mandatory background concepts. Next, the main datasets and challenges are exposed to help researchers decide which are the ones that best suit their needs and their targets. Then, existing methods are reviewed, highlighting their contributions and their significance in the field. Finally, quantitative results are given for the described methods and the datasets in which they were evaluated, following up with a discussion of the results. At last, we point out a set of promising future works and draw our own conclusions about the state of the art of semantic segmentation using deep learning techniques.},
archivePrefix = {arXiv},
arxivId = {1704.06857},
author = {Garcia-Garcia, Alberto and Orts-Escolano, Sergio and Oprea, Sergiu and Villena-Martinez, Victor and Garcia-Rodriguez, Jose},
doi = {10.1007/978-1-4471-4640-7},
eprint = {1704.06857},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/semantic-instance-review-2017.pdf:pdf},
pages = {1--23},
title = {{A Review on Deep Learning Techniques Applied to Semantic Segmentation}},
url = {http://arxiv.org/abs/1704.06857},
year = {2017}
}
@article{Srivastava2014,
abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different " thinned " networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
archivePrefix = {arXiv},
arxivId = {1102.4807},
author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
doi = {10.1214/12-AOS1000},
eprint = {1102.4807},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/srivastava14a.pdf:pdf},
isbn = {1532-4435},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {deep learning,model combination,neural networks,regularization},
pages = {1929--1958},
pmid = {23285570},
title = {{Dropout: A Simple Way to Prevent Neural Networks from Overfitting}},
volume = {15},
year = {2014}
}
@article{Oka2012,
abstract = {In this paper we propose a general method for contour recognition and DEM (Digital Elevation Models) generation from commercially available printed topographic maps. Automatic contour recognition of a scanned topographic map is a difficult problem due to the presence of closely spaced or broken contours, overlapping data layers and complexities arising from textured background etc. Beginning with a scanned map our approach utilizes a multistage process which broadly includes contour identification, cleaning and vectorization. While the identification and vectorization steps are based on calibrating existing image processing techniques, the cleaning step uses a modified geodesic distance based approach. The proposed technique was tested on contour regions of varying complexity scanned from a Survey of India toposheet of scale 1:50,000, scanned at 300 DPI. It was found that the proposed technique resulted in clean segmentation, crisp contour borders in the case of regular contour regions. However, differing levels of manual interventions were required to vectorize complex contour regions represented in the printed map. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
annote = {De klarer ganske bra {\aa} hente ut kontur linjer fra kart. Men tester bare en type kart.},
author = {Oka, Shriram and Garg, Akash and Varghese, Koshy},
doi = {10.1016/j.autcon.2011.06.017},
file = {:C$\backslash$:/Users/Ruben/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Oka, Garg, Varghese - 2012 - Vectorization of contour lines from scanned topographic maps.pdf:pdf},
isbn = {09265805 (ISSN)},
issn = {09265805},
journal = {Automation in Construction},
keywords = {Automated contour recognition,Contour maps,Digital elevation models,Geodesic distance,Topographic maps},
pages = {192--202},
publisher = {Elsevier B.V.},
title = {{Vectorization of contour lines from scanned topographic maps}},
url = {http://dx.doi.org/10.1016/j.autcon.2011.06.017},
volume = {22},
year = {2012}
}
@misc{Li,
author = {Karpathy, Andrej},
title = {{CS231n Convolutional Neural Networks for Visual Recognition}},
url = {http://cs231n.github.io/neural-networks-1/},
urldate = {2017-11-10}
}
@article{Szegedy2014,
abstract = {We propose a deep convolutional neural network ar- chitecture codenamed Inception that achieves the new state of the art for classification and detection in the Im- ageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the compu- tational budget constant. To optimize quality, the architec- tural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular in- carnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
archivePrefix = {arXiv},
arxivId = {1409.4842},
author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew and Hill, Chapel and Arbor, Ann},
doi = {10.1109/CVPR.2015.7298594},
eprint = {1409.4842},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/07298594.pdf:pdf},
isbn = {9781467369640},
issn = {10636919},
pages = {1--9},
pmid = {24920543},
title = {{Going Deeper with Convolutions}},
year = {2014}
}
@book{Patterson2017,
author = {Patterson, Josh and Gibson, Adam},
publisher = {O'Reilly Media},
title = {{Deep Learning: A Practitioner's Approach}},
year = {2017}
}
@article{Pearson2006,
annote = {Kilde p{\aa} hvorfor digitalisering av gamle kart kan v{\ae}re verdifult},
author = {Pearson, Alastair W},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/Pearson.pdf:pdf},
keywords = {agricultural history,georeferencing,gis,multilevel modelling,tithe maps},
number = {3},
pages = {178--193},
title = {{Digitizing and analyzing historical maps to provide new perspectives on the development of the agricultural landscape of England and Wales}},
volume = {1},
year = {2006}
}
@misc{Bo2009,
author = {B{\o}, Tore},
title = {{En veileder basert p{\aa} praktiske erfaringer fra Telemark og Vestfold}},
url = {https://kartverket.no/globalassets/plan/digitalisering-av-reguleringsplaner-telemark-vestfold.pdf},
year = {2009}
}
@article{Achanta2012,
abstract = {Computer vision applications have come to rely increasingly on superpixels in recent years, but it is not always clear what constitutes a good superpixel algorithm. In an effort to understand the benefits and drawbacks of existing methods, we empirically compare five state-of-the-art superpixel algorithms for their ability to adhere to image boundaries, speed, memory efficiency, and their impact on segmentation performance. We then introduce a new superpixel algorithm, simple linear iterative clustering (SLIC), which adapts a k-means clustering approach to efficiently generate superpixels. Despite its simplicity, SLIC adheres to boundaries as well as or better than previous methods. At the same time, it is faster and more memory efficient, improves segmentation performance, and is straightforward to extend to supervoxel generation.},
author = {Achanta, Radhakrishna and Shaji, Appu and Smith, Kevin and Lucchi, Aurelien and Fua, Pascal and S{\"{u}}sstrunk, Sabine},
doi = {10.1109/TPAMI.2012.120},
file = {:C$\backslash$:/Users/Ruben/Downloads/SLIC{\_}superpixels.pdf:pdf},
isbn = {0162-8828},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Superpixels,clustering,k-means,segmentation},
number = {11},
pages = {2274--2281},
pmid = {22641706},
title = {{SLIC superpixels compared to state-of-the-art superpixel methods}},
volume = {34},
year = {2012}
}
@book{Worboys2003,
abstract = {GIS: A Computing Perspective, Second Edition, provides a full, up-to-date overview of the state-of-the-art in GIS, both Geographic Information Systems and the study of these systems-Geographic Information Science. Analyzing the subject from a computing perspective, the second edition explores conceptual and formal models needed to understand spatial information, and examines the representations and data structures needed to support adequate system performance. This volume also covers the special-purpose interfaces and architectures required to interact with and share spatial information, and explains the importance of uncertainty and time. The material on GIS architectures and interfaces as well as spatiotemporal information systems is almost entirely new. The second edition contains substantial new information, and has been completely reformatted to improve accessibility. Changes include: There is also a new chapter on spatial uncertaintyComplete revisions of the bibliography, index, and supporting diagramsSupplemental material is offset at the top of the page, as are references and links for further studyDefinitions of new terms are in the margins of pages where they appear, with corresponding entries in the index},
author = {Worboys, Michael F.},
booktitle = {CRC press},
isbn = {0-7484-0065-6},
issn = {0028-8144},
pages = {376},
pmid = {41376455},
title = {{GIS: A computing perspective}},
year = {2003}
}
@article{Couclelis1992,
abstract = {A new approach to representing qualitative spatial knowledge and to spatial reasoning is presented. This approach is motivated by cognitive considerations and is based on relative orientation information about spatial environments. The approach aims at exploiting properties of physical space which surface when the spatial knowledge is structured according to conceptual neighborhood of spatial relations. The paper introduces the notion of conceptual neighborhood and its relevance for qualitative temporal reasoning. The extension of the benefits to spatial reasoning is suggested. Several approaches to qualitative spatial reasoning are briefly reviewed. Differences between the temporal and the spatial domain are outlined. A way of transferring a qualitative temporal reasoning method to the spatial domain is proposed. The resulting neighborhood-oriented representation and reasoning approach is presented and illustrated. An example for an application of the approach is discussed.},
author = {Couclelis, Helen},
doi = {10.1007/3-540-55966-3},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/People{\_}Manipulate{\_}Objects{\_}but{\_}Cultivate{\_}Fields{\_}Bey.pdf:pdf},
isbn = {978-3-540-55966-5},
issn = {03029743},
number = {July},
title = {{Theories and Methods of Spatio-Temporal Reasoning in Geographic Space}},
url = {http://link.springer.com/10.1007/3-540-55966-3},
volume = {639},
year = {1992}
}
@article{Ning2005,
abstract = {We describe a trainable system for analyzing videos of developing C. elegans embryos. The system automatically detects, segments, and locates cells and nuclei in microscopic images. The system was designed as the central component of a fully automated phenotyping system. The system contains three modules 1) a convolutional network trained to classify each pixel into five categories: cell wall, cytoplasm, nucleus membrane, nucleus, outside medium; 2) an energy-based model, which cleans up the output of the convolutional network by learning local consistency constraints that must be satisfied by label images; 3) a set of elastic models of the embryo at various stages of development that are matched to the label images.},
author = {Ning, Feng and Delhomme, Damien and LeCun, Yann and Piano, Fabio and Bottou, L{\'{e}}on and Barbano, Paolo Emilio},
doi = {10.1109/TIP.2005.852470},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/01495508.pdf:pdf},
isbn = {1057-7149 VO - 14},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Convolutional network,Energy-based model,Image segmentation,Nonlinear filter},
number = {9},
pages = {1360--1371},
pmid = {16190471},
title = {{Toward automatic phenotyping of developing embryos from videos}},
volume = {14},
year = {2005}
}
@article{Ciresan2011,
abstract = {We present a fast, fully parameterizable GPU implementation of Convolutional Neural Network variants. Our feature extractors are neither carefully designed nor pre-wired, but rather learned in a supervised way. Our deep hierarchical architectures achieve the best published results on benchmarks for object classification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with error rates of 2.53{\%}, 19.51{\%}, 0.35{\%}, respectively. Deep nets trained by simple back-propagation perform better than more shallow ones. Learning is surprisingly rapid. NORB is completely trained within five epochs. Test error rates on MNIST drop to 2.42{\%}, 0.97{\%} and 0.48{\%} after 1, 3 and 17 epochs, respectively.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Cireşan, Dan C. and Meier, Ueli and Masci, Jonathan and Gambardella, Luca M. and Schmidhuber, J{\"{u}}rgen},
doi = {10.5591/978-1-57735-516-8/IJCAI11-210},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/210.pdf:pdf},
isbn = {9781577355120},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {1237--1242},
pmid = {21310177},
title = {{Flexible, high performance convolutional neural networks for image classification}},
year = {2011}
}
@article{States2005,
author = {States, United},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/US20060041375.pdf:pdf},
isbn = {2005012173},
number = {12},
title = {{AUTOMATED GEOREFERENCING OF DIGITIZED MAP IMAGES}},
volume = {1},
year = {2005}
}
@article{Engineering2005,
annote = {Ulike algoritmer, kun p{\aa} {\aa} hente ut linjer.},
author = {Dharmaraj, Girija},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/05.20226.Girija-Dharmaraj.pdf:pdf},
number = {20226},
title = {{Algorithms for Automatic Vectorization of Scanned Maps}},
year = {2005}
}
@article{Long2014,
abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build "fully convolutional" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a novel architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20{\%} relative improvement to 62.2{\%} mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes one third of a second for a typical image.},
archivePrefix = {arXiv},
arxivId = {1411.4038},
author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
doi = {10.1109/TPAMI.2016.2572683},
eprint = {1411.4038},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/1411.4038.pdf:pdf},
isbn = {978-1-4673-6964-0},
issn = {01628828},
pmid = {16190471},
title = {{Fully Convolutional Networks for Semantic Segmentation}},
url = {http://arxiv.org/abs/1411.4038},
year = {2014}
}
@article{Kaiser2017,
abstract = {This study deals with semantic segmentation of high-resolution (aerial) images where a semantic class label is assigned to each pixel via supervised classification as a basis for automatic map generation. Recently, deep convolutional neural networks (CNNs) have shown impressive performance and have quickly become the de-facto standard for semantic segmentation, with the added benefit that task-specific feature design is no longer necessary. However, a major downside of deep learning methods is that they are extremely data-hungry, thus aggravating the perennial bottleneck of supervised classification, to obtain enough annotated training data. On the other hand, it has been observed that they are rather robust against noise in the training labels. This opens up the intriguing possibility to avoid annotating huge amounts of training data, and instead train the classifier from existing legacy data or crowd-sourced maps which can exhibit high levels of noise. The question addressed in this paper is: can training with large-scale, publicly available labels replace a substantial part of the manual labeling effort and still achieve sufficient performance? Such data will inevitably contain a significant portion of errors, but in return virtually unlimited quantities of it are available in larger parts of the world. We adapt a state-of-the-art CNN architecture for semantic segmentation of buildings and roads in aerial images, and compare its performance when using different training data sets, ranging from manually labeled, pixel-accurate ground truth of the same city to automatic training data derived from OpenStreetMap data from distant locations. We report our results that indicate that satisfying performance can be obtained with significantly less manual annotation effort, by exploiting noisy large-scale training data.},
archivePrefix = {arXiv},
arxivId = {1707.06879},
author = {Kaiser, Pascal and Wegner, Jan Dirk and Lucchi, Aurelien and Jaggi, Martin and Hofmann, Thomas and Schindler, Konrad},
doi = {10.1109/TGRS.2017.2719738},
eprint = {1707.06879},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/1707.06879.pdf:pdf},
issn = {01962892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
keywords = {Crowdsourcing,Image segmentation,Manuals,Roads,Semantics,Training,Training data,Urban areas,image classification,machine learning,neural networks,supervised learning,terrain mapping,urban areas},
pages = {1--15},
title = {{Learning Aerial Image Segmentation From Online Maps}},
year = {2017}
}
@article{Zangeneh2011,
abstract = {Potatoes are the single most important agricultural commodity in Hamadan province of Iran, where 25,503 ha of this crop were planted in 2008 under irrigated conditions. This paper compares results of the application of two different approaches, parametric model (PM) and artificial neural networks (ANNs), for assessing economical productivity (EP), total costs of production (TCP) and benefit to cost ratio (BC) of potato crop. In this comparison, Cobb-Douglas function for PM and multilayer feedforward for implementing ANN models have been used. The ANN, having 8-6-12-1 topology with R 2 = 0.89, resulted in the best-suited model for estimating EP. Similarly, optimal topologies for TCP and BC were 8-13-15-1 (R 2 = 0.97) and 8-15-13-1 (R 2 = 0.94), respectively. In validating the PM and ANN models, mean absolute percentage error (MAPE) was used as performance indicator. The ANN approach allowed to reduce the MAPE from –184{\%} for PM to less than 7{\%} with a +30{\%} to –95{\%} variability range. Since ANN outperformed PM model, it should be preferred for estimating economical indices. Resumen Estudio comparativo entre enfoques param{\'{e}}tricos y de redes neuronales artificiales para la evaluaci{\'{o}}n econ{\'{o}}mica de la producci{\'{o}}n de patata en Ir{\'{a}}n La patata es el producto agr{\'{i}}cola m{\'{a}}s importante en la provincia de Hamadan (Ir{\'{a}}n), donde se plantaron 25.503 ha de este cultivo en 2008 bajo condiciones de riego. Este trabajo compara los resultados de aplicar dos enfoques dife-rentes, un modelo param{\'{e}}trico (PM) y redes neuronales artificiales (ANN), para evaluar la productividad econ{\'{o}}mica (EP), los costos totales de producci{\'{o}}n (TCP) y el coeficiente beneficio/costo (BC) del cultivo de la patata. En esta comparaci{\'{o}}n se han utilizado la funci{\'{o}}n Cobb-Douglas como PM y el proceso " feedforward " multicapa para imple-mentar modelos de ANN. Las ANN, con una topolog{\'{i}}a 8-6-12-1 con R 2 = 0,89, resultaron ser el modelo m{\'{a}}s adecua-do para estimar la EP. Del mismo modo, las topolog{\'{i}}as {\'{o}}ptimas para TCP y BC fueron 8-13-15-1 (R 2 = 0,97) y 8-15-13-1 (R 2 = 0,94), respectivamente. Para validar los modelos PM y ANN, se utiliz{\'{o}} como indicador de desempe{\~{n}}o el error porcentual medio absoluto (MAPE). El enfoque de ANN permiti{\'{o}} reducir el MAPE desde –184{\%} para PM a me-nos del 7{\%} con un rango de variabilidad de +30{\%} a–95{\%}. Dado que ANN fue mejor que el modelo PM, debe ser pre-ferido para la estimaci{\'{o}}n de los {\'{i}}ndices econ{\'{o}}micos. Palabras clave adicionales: coeficiente beneficio/costo; costo total de producci{\'{o}}n; error de estimaci{\'{o}}n; funci{\'{o}}n de producci{\'{o}}n Cobb-Douglas; productividad econ{\'{o}}mica; redes neuronales artificiales; Solanum tuberosum. Abbreviations used: ANN (artificial neural network); BC (benefit to cost ratio); CER (cost estimation relationship); EP (econo-mical productivity, kg {\$} –1); MAE (mean absolute error); MAPE (mean absolute percentage error); MLP (multi layer perceptron); MSE (mean squared error); PM (parametric model); TCP (total cost of production, {\$} ha –1).},
annote = {Vectorisering uten masinl{\ae}ring},
author = {Zangeneh, M and Omid, M and Akram, A},
doi = {10.5424/http://dx.doi.org/10.5424/sjar/20110903-371-10},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/Zangenehetal.pdf:pdf},
isbn = {1695-971X},
issn = {2171-9292},
journal = {Instituto Nacional de Investigaci{\'{o}}n y Tecnolog{\'{i}}a Agraria y Alimentaria (INIA) Spanish Journal of Agricultural Research},
keywords = {Additional key words,Cobb-Douglas production function,Solanum tuberosum,artificial neural networks,benefit to cost ratio,eco-nomical productivity,estimation error,total cost of production},
number = {3},
pages = {661--671},
title = {{A comparative study between parametric and artificial neural networks approaches for economical assessment of potato production in Iran}},
url = {www.inia.es/sjar},
volume = {9},
year = {2011}
}
@article{Ciresan2012,
abstract = {We address a central problem of neuroanatomy, namely, the automatic segmentation of neuronal structures depicted in stacks of electron microscopy (EM) images. This is necessary to efﬁciently map 3D brain structure and connectivity. To segment biological neuron membranes, we use a special type of deep artiﬁcial neural network as a pixel classiﬁer. The label of each pixel (membrane or nonmembrane) is predicted from raw pixel values in a square window centered on it. The input layer maps each window pixel to a neuron. It is followed by a succession of convolutional and max-pooling layers which preserve 2D information and extract features with increasing levels of abstraction. The output layer produces a calibrated probability for each class. The classiﬁer is trained by plain gradient descent on a 512  512  30 stack with known ground truth, and tested on a stack of the same size (ground truth unknown to the authors) by the organizers of the ISBI 2012 EM Segmentation Challenge. Even without problem-speciﬁc postprocessing, our approach outperforms competing techniques by a large margin in all three considered metrics, i.e. rand error, warping error and pixel error. For pixel error, our approach is the only one outperforming a second human observer.},
annote = {Henter ut linjer fra electron microscopy.},
author = {Ciresan, Dc and Giusti, Alessandro and Gambardella, Lm and Schmidhuber, J},
doi = {10.1.1.300.2221},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/nips2012.pdf:pdf},
isbn = {9781627480031},
issn = {10495258},
journal = {Nips},
pages = {1--9},
title = {{Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images}},
url = {https://papers.nips.cc/paper/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images.pdf},
year = {2012}
}
@article{Henderson,
author = {Henderson, Thomas C and Linton, Trevor and Potupchik, Sergey and Ostanin, Andrei},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/Automatic{\_}segmentation{\_}of{\_}semanticclasses{\_}in{\_}raster{\_}map{\_}images.pdf:pdf},
keywords = {graphics recognition,raster map images,segmentation},
title = {{Automatic Segmentation of Semantic Classes in Raster Map Images}}
}
@article{Visin2015,
abstract = {In this paper, we propose a deep neural network architecture for object recognition based on recurrent neural networks. The proposed network, called ReNet, replaces the ubiquitous convolution+pooling layer of the deep convolutional neural network with four recurrent neural networks that sweep horizontally and vertically in both directions across the image. We evaluate the proposed ReNet on three widely-used benchmark datasets; MNIST, CIFAR-10 and SVHN. The result suggests that ReNet is a viable alternative to the deep convolutional neural network, and that further investigation is needed.},
archivePrefix = {arXiv},
arxivId = {1505.00393},
author = {Visin, Francesco and Kastner, Kyle and Cho, Kyunghyun and Matteucci, Matteo and Courville, Aaron and Bengio, Yoshua},
doi = {10.1109/CVPR.2016.399},
eprint = {1505.00393},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/1505.00393.pdf:pdf},
isbn = {9781577357384},
issn = {10450823},
pages = {1--9},
title = {{ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks}},
url = {http://arxiv.org/abs/1505.00393},
year = {2015}
}
@article{Armstrong2006,
author = {Armstrong, Curtis A},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/Armstrong - 2006 - Vectorization of Raster Images Using B-Spline Surfaces.pdf:pdf},
keywords = {vector video research preparation,矢量视频调研},
number = {July},
pages = {166},
title = {{Vectorization of Raster Images Using B-Spline Surfaces}},
year = {2006}
}
@article{Zeiler2011,
author = {Zeiler, Matthew D and Taylor, Graham W and Fergus, Rob},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/06126474.pdf:pdf},
isbn = {9781457711022},
pages = {2018--2025},
title = {{Adaptive Deconvolutional Networks for Mid and High Level Feature Learning}},
year = {2011}
}
@article{Krahenbuhl2012,
abstract = {Most state-of-the-art techniques for multi-class image segmentation and labeling use conditional random fields defined over pixels or image regions. While region-level models often feature dense pairwise connectivity, pixel-level models are considerably larger and have only permitted sparse graph structures. In this paper, we consider fully connected CRF models defined on the complete set of pixels in an image. The resulting graphs have billions of edges, making traditional inference algorithms impractical. Our main contribution is a highly efficient approximate inference algorithm for fully connected CRF models in which the pairwise edge potentials are defined by a linear combination of Gaussian kernels. Our experiments demonstrate that dense connectivity at the pixel level substantially improves segmentation and labeling accuracy.},
annote = {Veldig bra edge detection!},
archivePrefix = {arXiv},
arxivId = {1210.5644},
author = {Kr{\"{a}}henb{\"{u}}hl, Philipp and Koltun, Vladlen},
eprint = {1210.5644},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/1210.5644.pdf:pdf},
isbn = {9781618395993},
issn = {9781618395993},
pages = {1--9},
title = {{Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials}},
url = {http://arxiv.org/abs/1210.5644},
year = {2012}
}
@misc{PASCALVOC2012,
author = {{PASCAL VOC}},
title = {{PASCAL VOC2011}},
url = {http://host.robots.ox.ac.uk/pascal/VOC/voc2012/segexamples/index.html},
urldate = {2017-11-08},
year = {2012}
}
@article{Daniil2003,
abstract = {The introduction of modern digital imaging techniques to historical cartography, especially in documenting old map collections, meets the need for extending and applying image processing and relevant photogrammetric tools to the analysis of antique maps in a context in which digital photogrammetry intersects modern theories of digital treatment of old maps. The authors discuss some aspects of controlling the geometric features of the scanned images of antique maps in terms, e.g., of linear, angular, and areal deformation. Collateral effects influencing the scanned map image are also described--namely, the statistics and the image quality of the output map images with respect to the original map and/or the "reference" digital best-scanned image.},
author = {Daniil, M and Tsioukas, V and Papadopoulos, K and Livieratos, E},
file = {:C$\backslash$:/Users/Ruben/Documents/prosjektoppgave/kilder/Scanning{\_}options{\_}and{\_}choices{\_}in{\_}digitizing{\_}histori.pdf:pdf},
isbn = {975-561-245-9},
journal = {Proceedings of the XIXth International Symposium, CIPA 2003: new perspectives to save cultural heritage: Antalya (Turkey), 30 September-04 October, 2003},
keywords = {cartography,data processing,digital imaging,maps,photogrammetry},
number = {January},
pages = {99--102},
title = {{Scanning options and choices in digitizing historic maps}},
year = {2003}
}
