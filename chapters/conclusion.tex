\chapter{Conclusion}
DCNNs have shown great ability to do dense predictions of semantic labels in images with accuracy up to 86.9\% on the VOC2012 dataset. Huge datasets have been made for the training of these nets and data availability seems to be the biggest factor in success nowadays, but recent approaches such as CapsNet \cite{Sabour2017} try to lower the demand for data.

Some of the approaches using existing open source tools show interesting results in vectorization, but the need for uniform and similar maps does however limit the application when working with maps of different quality.

With the performance seen in the results of the DCNNs reviewed in this paper, there is no reason to believe that they should not be able to vectorize the zoning regulations as proposed. However, one of the biggest challenges found is the need to create a specific dataset. There was however no straight forward way to create the dataset automatic.

If such dataset is created, either manually, automatically or by crowd sourcing, the work proposed in this paper could greatly speed up the process of vectorizing old zoning regulations by automating the whole process. Automation could yield substantial economic savings and an effort should be given to evaluating different methods in order to do so.