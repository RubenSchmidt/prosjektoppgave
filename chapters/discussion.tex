\chapter{Discussion}
As we can see from the previous work, little research has been done in regards to using DCNN to vectorize scanned raster maps. Many of the traditional algorithms used for vectorization seen in \autoref{chp:vectorization}, specialize in the recognition of lines or known shapes. Most of the related work is also focusing on the extraction of linear features, such as contour lines and roads. DCNN show great ability to learn and segment images if trained properly and should, therefore, be able to vectorize raster maps if one could generate a dataset with training data.

Looking at the more traditional approaches not using neural networks to solve the problem, we see some interesting results. The benefit of the image analysis approach is that it does not require any training data and relies solely on the analysis itself. The downside, as seen in many of the reviewed papers is that one often needs to tune the algorithm and images for each specific case. For instance one of the steps in \citet{Iosifescu2016}, is to convert the image to a binary one, that is, converting it to contain only two colors. We see similar steps in the other papers, where they more than often convert the problem to a simpler one with pre-processing or binarization.

For the zoning regulations, the zone color is one of the important aspects of the plan that cannot be ignored, as it describes what the allowed usage of that zone is. The plans are also of different quality as seen in \autoref{chp:dataset}, so the method needs to generalize well beyond the training samples in order to extract the polygons from different quality PDFs. This is not something we have seen in the previous work focusing on traditional methods. On the opposite side, generalizing beyond training samples is where DCNNs have shown great ability. In addition to vectorizing the polygon in the plan, with the perfomance of DCNN making dense predictions and assigning classes to objects, it should be possible to try to label the specific zoning type for the polygon.


